{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Pretrained LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture\n",
    "class LSTMNameGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_size=32, dropout=0.2, char2int=None, int2char=None):\n",
    "        super(LSTMNameGenerator, self).__init__()\n",
    "\n",
    "        # useful model properties\n",
    "        self.vocab_size = vocab_size        \n",
    "        self.char2int = char2int\n",
    "        self.int2char = int2char\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # embedding layer is useful to map input into vector representation\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "\n",
    "        # LSTM layer preserved by PyTorch library\n",
    "        # this layer handles LSTM Cell loops\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # Linear layer for output\n",
    "        self.output = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, h=None, c=None):\n",
    "        # its optional to init hidden state by ourselves\n",
    "        # bcs PyTorch will handle it if we don't provide it\n",
    "\n",
    "        # map input to vector\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # compute current hidden state\n",
    "        if h != None and c != None:\n",
    "            o, (h, c) = self.lstm(x, (h, c))\n",
    "        else:\n",
    "            o, (h, c) = self.lstm(x, None)\n",
    "\n",
    "        # apply dropout\n",
    "        o = self.dropout(o)\n",
    "\n",
    "        # compute output\n",
    "        o = self.output(o)\n",
    "\n",
    "        # here we return hidden state too cz we want to use it in inference mode\n",
    "        return o, h, c\n",
    "\n",
    "    def init_hidden(self, device):\n",
    "        return torch.randn(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HID_SIZE = 128\n",
    "EMB_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('../models/name_genLSTM.pt')\n",
    "vocab = pickle.load(open('../models/vocab.pkl', 'rb'))\n",
    "int2char = pickle.load(open('../models/vocab_int2char.pkl', 'rb'))\n",
    "\n",
    "gen = LSTMNameGenerator(len(vocab), HID_SIZE, EMB_SIZE, char2int=vocab, int2char=int2char)\n",
    "gen.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMNameGenerator(\n",
       "  (embedding): Embedding(56, 64)\n",
       "  (lstm): LSTM(64, 128, batch_first=True)\n",
       "  (output): Linear(in_features=128, out_features=56, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(model, phrase=None, max_length=6, temperature=1.0, top_k=None):\n",
    "    # x_enc = [[vocab[ch] for ch in phrase]]\n",
    "    x_enc = [[0]]\n",
    "    # x_pad = pad_features(x_enc, max_length)\n",
    "    x_torch = torch.tensor(x_enc, dtype=torch.int64, device=device)\n",
    "\n",
    "    # create list for output\n",
    "    char_out = phrase.split()\n",
    "\n",
    "    # move to device\n",
    "    x_torch = x_torch\n",
    "\n",
    "    # init empty hidden state\n",
    "    h = c = model.init_hidden(device)\n",
    "\n",
    "    # running through seed phrase to generate hidden_state\n",
    "    # here we leave the last character cz we will feed it in\n",
    "    # the generating phase as the first sequence\n",
    "    for i in range(len(phrase)-1):\n",
    "        out, h, c = model(x_torch[:, i:i+1], h, c)\n",
    "\n",
    "    # start generating\n",
    "    for _ in range(max_length - len(phrase)):\n",
    "        out, h, c = model(x_torch[:, -1:], h, c)\n",
    "        # p = F.softmax(out / temperature, dim=-1).data        \n",
    "        p = F.gumbel_softmax(out, 1).data        \n",
    "\n",
    "        # pick top K token by top_k (if defined)\n",
    "        if top_k is None:\n",
    "            top_char = np.arange(len(vocab))\n",
    "        else:\n",
    "            p, top_char = p.topk(top_k).detach()\n",
    "            top_char = top_char.cpu().numpy().squeeze()        \n",
    "\n",
    "        # select next token and push it to input sequence\n",
    "        p = p.cpu().numpy().squeeze()\n",
    "        char_id = np.random.choice(top_char, p=p/p.sum())\n",
    "        char = torch.tensor([[char_id]], dtype=torch.int64, device=device)\n",
    "        x_torch = torch.cat([x_torch, char], dim=-1)\n",
    "    \n",
    "        # push to char_out too\n",
    "        char_out.append(int2char[char_id] if char_id > 0 else ' ')\n",
    "\n",
    "    return ''.join(char_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample(gen, phrase='', max_length=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "PATH = '../data/names.txt'\n",
    "\n",
    "with open(PATH, 'r', encoding='utf-8') as r:\n",
    "    names = r.read().split('\\n')\n",
    "\n",
    "# shuffle dataset\n",
    "index = list(range(len(names)))\n",
    "random.shuffle(index)\n",
    "names = [names[i] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[37, 3, 27, 55, 3, 51],\n",
       " [33, 26, 50, 40, 32, 1, 51, 3, 26],\n",
       " [16, 50, 40, 32, 26, 26],\n",
       " [21, 52, 40, 3, 3, 55, 3],\n",
       " [2, 32, 55, 27, 51, 32, 1, 40]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build vocab\n",
    "chars = tuple(set(''.join(names)))\n",
    "int2char = dict(enumerate(chars, 1))\n",
    "int2char[0] = '<PAD>'\n",
    "char2int = {v: k for k, v in int2char.items()}\n",
    "\n",
    "# encode words\n",
    "names_enc = [[char2int[ch] for ch in name] for name in names]\n",
    "names_enc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37,  3, 27, 55,  3, 51,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [33, 26, 50, 40, 32,  1, 51,  3, 26,  0,  0,  0,  0,  0,  0],\n",
       "       [16, 50, 40, 32, 26, 26,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [21, 52, 40,  3,  3, 55,  3,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2, 32, 55, 27, 51, 32,  1, 40,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad features\n",
    "seq_length = max([len(x) for x in names_enc])\n",
    "\n",
    "def pad_features(names, seq_length):\n",
    "    features = np.zeros((len(names), seq_length), dtype=int)    \n",
    "\n",
    "    for i, row in enumerate(names):\n",
    "        # if seq_length < len(row) then row will be trimmed (expected)        \n",
    "        features[i, :len(row)] = np.array(row)[:seq_length]\n",
    "\n",
    "    return features\n",
    "\n",
    "features = pad_features(names_enc, seq_length)\n",
    "\n",
    "assert len(features) == len(names_enc)\n",
    "assert len(features[0]) == seq_length\n",
    "\n",
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Shapes:\n",
      "===============\n",
      "Train set: (5958, 15)\n",
      "Test set: (1986, 15)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "train_size = .75     # we will use 80% of data as train set\n",
    "# val_size = .5       # we will use 50% of test set as validation set\n",
    "\n",
    "split_id = int(len(features) * train_size)\n",
    "train_x, test_x = features[:split_id], features[split_id:]\n",
    "\n",
    "# test_id = int(len(remain_x) * val_size)\n",
    "# val_x, test_x = remain_x[:test_id], remain_x[test_id:]\n",
    "\n",
    "print('Feature Shapes:')\n",
    "print('===============')\n",
    "print('Train set: {}'.format(train_x.shape))\n",
    "# print('Validation set: {}'.format(val_x.shape))\n",
    "print('Test set: {}'.format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate batches\n",
    "batch_size = 128\n",
    "\n",
    "trainset = TensorDataset(torch.from_numpy(train_x))\n",
    "# validset = TensorDataset(torch.from_numpy(val_x))\n",
    "testset = TensorDataset(torch.from_numpy(test_x))\n",
    "\n",
    "trainloader = DataLoader(trainset, shuffle=True, batch_size=batch_size)\n",
    "# validloader = DataLoader(validset, shuffle=True, batch_size=batch_size)\n",
    "testloader = DataLoader(testset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch size:  torch.Size([128, 15])\n",
      "Sample batch input: \n",
      " tensor([[39, 40, 50,  ...,  0,  0,  0],\n",
      "        [21, 52, 26,  ...,  0,  0,  0],\n",
      "        [35, 26, 50,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 2, 52, 40,  ...,  0,  0,  0],\n",
      "        [ 4, 51, 50,  ...,  0,  0,  0],\n",
      "        [18,  6,  6,  ...,  0,  0,  0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "diter = iter(trainloader)\n",
    "x = diter.next()[0]\n",
    "\n",
    "print('Sample batch size: ', x.size())   # batch_size, seq_length\n",
    "print('Sample batch input: \\n', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNameDiscriminator(nn.Module):\n",
    "    def __init__(self, vocab_size, out_size, hid_size=64, emb_size=32):\n",
    "        super(LSTMNameDiscriminator, self).__init__()\n",
    "\n",
    "        # embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(emb_size, hid_size, batch_first=True)\n",
    "\n",
    "        # linear layer\n",
    "        self.output = nn.Linear(hid_size, out_size)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # map input to vector\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # compute current hidden state\n",
    "        o, _ = self.lstm(x)\n",
    "\n",
    "        # get last sequence output\n",
    "        o = o[:, -1, :]\n",
    "\n",
    "        # feed output to linear layer\n",
    "        logit = self.output(o)\n",
    "\n",
    "        out = self.sigmoid(logit)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMNameDiscriminator(\n",
       "  (embedding): Embedding(56, 64)\n",
       "  (lstm): LSTM(64, 128, batch_first=True)\n",
       "  (output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc = LSTMNameDiscriminator(len(vocab), 1, HID_SIZE, EMB_SIZE)\n",
    "disc.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.tensor([[1]]), torch.tensor([[1]]), torch.tensor([[1]])], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake(model, batch_size=batch_size, max_length=12, tau=1.0, noise=None):\n",
    "    # X_enc = torch.zeros((batch_size, 1), dtype=torch.int64, device=device)\n",
    "    X_enc = torch.tensor([], device=device, dtype=torch.int64)\n",
    "\n",
    "    generated = []\n",
    "\n",
    "    # insert noise to hidden and cell state\n",
    "    if noise == None:\n",
    "        h = c = model.init_hidden(device)\n",
    "    else:\n",
    "        h = c = noise\n",
    "\n",
    "    for _ in range(batch_size):\n",
    "        X_interim = torch.tensor([], device=device, dtype=torch.int64)\n",
    "        char_out = []\n",
    "        # start generating\n",
    "        for _ in range(max_length):\n",
    "            X = torch.zeros((1, 1), dtype=torch.int64, device=device)\n",
    "            out, h, c = model(X, h, c)\n",
    "\n",
    "            # apply gumbel softmax here\n",
    "            p = F.gumbel_softmax(out, tau=tau).data\n",
    "\n",
    "            top_char = np.arange(len(vocab))\n",
    "            p = p.cpu().numpy().squeeze()\n",
    "            char_id = np.random.choice(top_char, p=p/p.sum())\n",
    "            char = torch.tensor([[char_id]], dtype=torch.int64, device=device)\n",
    "            X_interim = torch.cat([X_interim, char], dim=-1)\n",
    "\n",
    "            char_out.append(int2char[char_id] if char_id > 0 else ' ')\n",
    "        \n",
    "        generated.append(char_out)\n",
    "        X_enc = torch.cat([X_enc, X_interim], dim=0)\n",
    "\n",
    "    return X_enc, generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[42,  0,  0,  1, 13,  0, 27,  0,  0,  0, 46,  0],\n",
       "         [ 0,  0, 52, 37,  0, 10, 55,  0,  0,  0, 12, 40],\n",
       "         [ 0, 28,  0,  0, 23,  0,  0,  0, 13,  0, 46,  0],\n",
       "         [18, 36,  0,  0, 23,  0, 25,  0,  0,  0,  0, 37],\n",
       "         [ 0, 42, 54,  0,  4,  0,  4, 47, 32,  0, 18,  0],\n",
       "         [ 0,  0, 38,  0,  0,  0,  0,  0, 42, 30,  0,  0],\n",
       "         [ 0,  0, 54,  0,  0, 28,  0,  0, 24, 28,  0,  0],\n",
       "         [ 0, 46,  3,  0,  0, 30,  0,  0, 28, 42, 52,  0],\n",
       "         [20,  1,  0, 42,  0, 28, 13,  1, 38,  0, 28,  0],\n",
       "         [ 0, 46,  0,  0, 23,  0,  0, 52,  0,  0, 38,  3]], device='cuda:0'),\n",
       " [['U', ' ', ' ', 'd', \"'\", ' ', 't', ' ', ' ', ' ', 'b', ' '],\n",
       "  [' ', ' ', 'h', 'A', ' ', 'u', 'o', ' ', ' ', ' ', 'Q', 'a'],\n",
       "  [' ', 'L', ' ', ' ', 'I', ' ', ' ', ' ', \"'\", ' ', 'b', ' '],\n",
       "  ['E', 's', ' ', ' ', 'I', ' ', 'P', ' ', ' ', ' ', ' ', 'A'],\n",
       "  [' ', 'U', 'x', ' ', 'M', ' ', 'M', 'F', 'l', ' ', 'E', ' '],\n",
       "  [' ', ' ', 'k', ' ', ' ', ' ', ' ', ' ', 'U', 'W', ' ', ' '],\n",
       "  [' ', ' ', 'x', ' ', ' ', 'L', ' ', ' ', 'X', 'L', ' ', ' '],\n",
       "  [' ', 'b', 'n', ' ', ' ', 'W', ' ', ' ', 'L', 'U', 'h', ' '],\n",
       "  ['Y', 'd', ' ', 'U', ' ', 'L', \"'\", 'd', 'k', ' ', 'L', ' '],\n",
       "  [' ', 'b', ' ', ' ', 'I', ' ', ' ', 'h', ' ', ' ', 'k', 'n']])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, fake = generate_fake(gen, batch_size=10, tau=5)\n",
    "X, fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "opt_gen = Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = Adam(gen.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "num_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = gen.init_hidden(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bdefc658194c2c9d28bcae8a5022d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5e6885f233424990df115edf031fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100 Batch 0/47] | Loss D: 1.3758, loss G: 0.0706\n",
      "Generated: 'S  a  A  U \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1e5190e8d14707a1106e1e53720849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100 Batch 0/47] | Loss D: 1.3765, loss G: 0.0693\n",
      "Generated: CZ      r  v\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4416b938209c4435bddca67393c17484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100 Batch 0/47] | Loss D: 1.3787, loss G: 0.0649\n",
      "Generated: In      YP k\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9860079cc2b416693fbe4cf6838eae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100 Batch 0/47] | Loss D: 1.3810, loss G: 0.0599\n",
      "Generated: W    v    cH\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158accd7452741db960a71d8a96a09e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100 Batch 0/47] | Loss D: 1.3803, loss G: 0.0616\n",
      "Generated:  A 'u PVY F \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21754bc2785425480c4b333429db3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100 Batch 0/47] | Loss D: 1.3751, loss G: 0.0723\n",
      "Generated: Z  a   Zc h \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c645ac01f78f4cf0ba6a83230b9e7e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100 Batch 0/47] | Loss D: 1.3758, loss G: 0.0705\n",
      "Generated: c      F   U\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d58ab1a98a4541b18c853944e2e702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100 Batch 0/47] | Loss D: 1.3789, loss G: 0.0642\n",
      "Generated: Y k g Q     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbfa10f1d96428fb1281b2ce5d7d657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100 Batch 0/47] | Loss D: 1.3749, loss G: 0.0725\n",
      "Generated: Ig      U   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6734bb94f8924482bd36bebf35749469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100 Batch 0/47] | Loss D: 1.3780, loss G: 0.0663\n",
      "Generated:  M 'LZ      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049e08fc4e944089b3798d19934fae41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100 Batch 0/47] | Loss D: 1.3761, loss G: 0.0699\n",
      "Generated:  L  g N     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9ed1d73a9842f2aa57e5acb55c4aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100 Batch 0/47] | Loss D: 1.3775, loss G: 0.0674\n",
      "Generated:   VUM     Z \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ee8993846a4128b5c232c46cf4b5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100 Batch 0/47] | Loss D: 1.3775, loss G: 0.0673\n",
      "Generated:  e Mn'   w M\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1b0d5beb4e456798c3dea578ad15aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100 Batch 0/47] | Loss D: 1.3780, loss G: 0.0661\n",
      "Generated:  Ua L   gb R\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1391993c1232450e9d3ef18b83f03167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100 Batch 0/47] | Loss D: 1.3762, loss G: 0.0702\n",
      "Generated:  bz  t  M  R\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62452166c89f4603b3ac1ecd027d5e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100 Batch 0/47] | Loss D: 1.3797, loss G: 0.0627\n",
      "Generated:  U L Z   G  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3953bedd649f4d54bb58a0a71fb18acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100 Batch 0/47] | Loss D: 1.3775, loss G: 0.0672\n",
      "Generated: o  b   u RPY\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f142ea1e7144b088054697f2725bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100 Batch 0/47] | Loss D: 1.3761, loss G: 0.0701\n",
      "Generated:       n    c\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b760b51903684b558f6da3b6d818281d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100 Batch 0/47] | Loss D: 1.3779, loss G: 0.0661\n",
      "Generated: B d  b  ' n \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8516bf8012574e77b469ee2521d8b0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100 Batch 0/47] | Loss D: 1.3773, loss G: 0.0675\n",
      "Generated:  Phg     Fbv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ae402a0bce49a29a2506b40e0e6d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100 Batch 0/47] | Loss D: 1.3800, loss G: 0.0622\n",
      "Generated:  M PZ -A    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f99d334c314b03916b27f67e188114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100 Batch 0/47] | Loss D: 1.3759, loss G: 0.0708\n",
      "Generated: I nE  P Hb  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114ebc0e8f544680be36b0c4e76794f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100 Batch 0/47] | Loss D: 1.3789, loss G: 0.0646\n",
      "Generated:    b  o     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97ff664f00841b89e8d2ce11450eb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100 Batch 0/47] | Loss D: 1.3780, loss G: 0.0663\n",
      "Generated: W  W       u\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09fd791132034b35818a145895a8d548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100 Batch 0/47] | Loss D: 1.3759, loss G: 0.0704\n",
      "Generated: HB HN       \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0168cd89ec4e1cbcbec99a45d94a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100 Batch 0/47] | Loss D: 1.3782, loss G: 0.0660\n",
      "Generated: o   P lE    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e947d83ccd74781a1fda3e55226e426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100 Batch 0/47] | Loss D: 1.3773, loss G: 0.0676\n",
      "Generated:    Z YebEP z\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab2d2a6625541958fb67c29d81c2a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100 Batch 0/47] | Loss D: 1.3792, loss G: 0.0638\n",
      "Generated: UWE R cPd   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580e23396cb940748816bae43f676bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100 Batch 0/47] | Loss D: 1.3805, loss G: 0.0612\n",
      "Generated:    gu mP    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04376bec1c84a8b83c4126d9a0f8fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100 Batch 0/47] | Loss D: 1.3768, loss G: 0.0687\n",
      "Generated:  TR  V  bP M\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccf6b71fa1540a5bdf8a09a6d323db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100 Batch 0/47] | Loss D: 1.3761, loss G: 0.0701\n",
      "Generated: e UPw       \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c9a6e5bfd544c693979dab447fa782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100 Batch 0/47] | Loss D: 1.3798, loss G: 0.0623\n",
      "Generated: tY U    '  L\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8207dec22728415794c853e83be30530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100 Batch 0/47] | Loss D: 1.3766, loss G: 0.0691\n",
      "Generated: C Pbs  ldU  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777394383ecf4372b63387e78ca6aebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100 Batch 0/47] | Loss D: 1.3782, loss G: 0.0659\n",
      "Generated: kNl  lP   cL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7886e5c4f7374aaea1d416df1d0d161a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100 Batch 0/47] | Loss D: 1.3761, loss G: 0.0706\n",
      "Generated: - Vu  N cl P\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a457cfcdf0d343bdb5f964e497d7d9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100 Batch 0/47] | Loss D: 1.3785, loss G: 0.0654\n",
      "Generated: X t  z      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ef4757cfc94624bb872fe529ba9152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100 Batch 0/47] | Loss D: 1.3791, loss G: 0.0641\n",
      "Generated:  bU tL P W  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c106bf6b2ea24230b19783bcc36c50cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100 Batch 0/47] | Loss D: 1.3811, loss G: 0.0601\n",
      "Generated: M  PCh  V   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315e7eb81f474247b0dc2aeff8e74a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100 Batch 0/47] | Loss D: 1.3808, loss G: 0.0605\n",
      "Generated:     UMhVg   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c316d872c98e4e8890aeefd96df3c99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100 Batch 0/47] | Loss D: 1.3766, loss G: 0.0691\n",
      "Generated: Pc   bh b I \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865a82f1e6e94b038b0f752ab7fdee0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100 Batch 0/47] | Loss D: 1.3796, loss G: 0.0629\n",
      "Generated: t     w W   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e5b6b52e0b415499349ea334581a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100 Batch 0/47] | Loss D: 1.3788, loss G: 0.0646\n",
      "Generated: H lM'h     b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7311739d1a4a0a8a4831a30e8b9546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100 Batch 0/47] | Loss D: 1.3794, loss G: 0.0634\n",
      "Generated: gtn    W P  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\myproject\\all-about-rnn\\char-rnn\\notebook\\inference.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/myproject/all-about-rnn/char-rnn/notebook/inference.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m real \u001b[39m=\u001b[39m real[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/myproject/all-about-rnn/char-rnn/notebook/inference.ipynb#X32sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Train Discriminator\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/myproject/all-about-rnn/char-rnn/notebook/inference.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m fake, _ \u001b[39m=\u001b[39m generate_fake(gen, batch_size\u001b[39m=\u001b[39;49mbatch_size, tau\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/myproject/all-about-rnn/char-rnn/notebook/inference.ipynb#X32sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m disc_real \u001b[39m=\u001b[39m disc(real)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/myproject/all-about-rnn/char-rnn/notebook/inference.ipynb#X32sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# lossD_real = criterion(disc_real, torch.ones_like(disc_real))\u001b[39;00m\n",
      "\u001b[1;32me:\\myproject\\all-about-rnn\\char-rnn\\notebook\\inference.ipynb Cell 26\u001b[0m in \u001b[0;36mgenerate_fake\u001b[1;34m(model, batch_size, max_length, tau, noise)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/myproject/all-about-rnn/char-rnn/notebook/inference.ipynb#X32sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m p \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/myproject/all-about-rnn/char-rnn/notebook/inference.ipynb#X32sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m char_id \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(top_char, p\u001b[39m=\u001b[39mp\u001b[39m/\u001b[39mp\u001b[39m.\u001b[39msum())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/myproject/all-about-rnn/char-rnn/notebook/inference.ipynb#X32sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m char \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor([[char_id]], dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mint64, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/myproject/all-about-rnn/char-rnn/notebook/inference.ipynb#X32sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m X_interim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([X_interim, char], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/myproject/all-about-rnn/char-rnn/notebook/inference.ipynb#X32sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m char_out\u001b[39m.\u001b[39mappend(int2char[char_id] \u001b[39mif\u001b[39;00m char_id \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epoch), desc='Epochs'):\n",
    "\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    for batch_idx, real in enumerate(tqdm(trainloader, desc='Batch')):\n",
    "        \n",
    "        real = real[0].to(device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        fake, _ = generate_fake(gen, batch_size=batch_size, tau=5)\n",
    "        disc_real = disc(real).view(-1)\n",
    "        # lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        lossD_real = -1 * torch.mean(torch.log(disc_real))\n",
    "\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        # lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD_fake = -1 * torch.mean(torch.log(1 - disc_fake))\n",
    "\n",
    "        # lossD = (lossD_real + lossD_fake) / 2\n",
    "        lossD = (lossD_real + lossD_fake)\n",
    "\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "\n",
    "        # Train Generator\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = -1 * torch.mean(torch.log(output/(1 - output)))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f'Epoch [{epoch}/{num_epoch} Batch {batch_idx}/{len(trainloader)}] | Loss D: {lossD:.4f}, loss G: {lossG:.4f}'\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():    \n",
    "                _, fake_gen = generate_fake(gen, batch_size=1, tau=5, noise=fixed_noise)\n",
    "                print(f'Generated: {\"\".join(fake_gen[0])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8564a27cb82d73423f8ef7649afe412fe88be26d8d7a10840ebe1fcfca8dcfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
